#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
EPUB ç« èŠ‚å¯¼å‡ºå·¥å…· v2.0
åŸºäº ebooklib æ ‡å‡†æ–¹æ³•çš„ç®€åŒ–å®ç°ï¼Œé¿å…å¤æ‚çš„è‡ªåˆ¶é”šç‚¹å¤„ç†ç®—æ³•
"""

import os
import sys
import tempfile
import shutil
from pathlib import Path
import click
import ebooklib
from ebooklib import epub
import pypandoc
import re
from typing import List, Tuple, Optional
from html import unescape


class EpubExporterV2:
    """EPUB å¯¼å‡ºå™¨ v2.0 - åŸºäºæ ‡å‡†æ–¹æ³•çš„ç®€åŒ–å®ç°"""
    
    def __init__(self, epub_path: str):
        """
        åˆå§‹åŒ– EPUB å¯¼å‡ºå™¨
        
        Args:
            epub_path: EPUB æ–‡ä»¶è·¯å¾„
        """
        self.epub_path = Path(epub_path)
        self.book = None
        self.temp_dir = None
        
        if not self.epub_path.exists():
            raise FileNotFoundError(f"EPUB æ–‡ä»¶ä¸å­˜åœ¨: {epub_path}")
            
    def load_epub(self) -> None:
        """åŠ è½½ EPUB æ–‡ä»¶"""
        try:
            self.book = epub.read_epub(str(self.epub_path))
            print(f"âœ“ æˆåŠŸåŠ è½½ EPUB æ–‡ä»¶: {self.epub_path.name}")
        except Exception as e:
            raise Exception(f"æ— æ³•åŠ è½½ EPUB æ–‡ä»¶: {e}")
    
    def get_chapters(self, debug=False) -> List[Tuple[str, str, str]]:
        """
        è·å–æ‰€æœ‰ç« èŠ‚å†…å®¹ - ä½¿ç”¨æ ‡å‡†æ–¹æ³•
        
        Args:
            debug: æ˜¯å¦è¾“å‡ºè°ƒè¯•ä¿¡æ¯
            
        Returns:
            List of (chapter_title, chapter_content, chapter_id)
        """
        if not self.book:
            self.load_epub()
            
        if debug:
            self._print_epub_structure()
            
        chapters = []
        
        # æ–¹æ³•1: ä¼˜å…ˆä½¿ç”¨ TOC (ç›®å½•) ç»“æ„
        if self.book.toc:
            if debug:
                print(f"\nğŸ“– ä½¿ç”¨ TOC ç»“æ„æå–ç« èŠ‚")
            chapters = self._extract_from_toc_standard(debug)
        
        # æ–¹æ³•2: å¦‚æœ TOC ä¸ºç©ºæˆ–æå–å¤±è´¥ï¼Œä½¿ç”¨ Spine é¡ºåº
        if not chapters:
            if debug:
                print(f"\nğŸ“„ TOC æå–å¤±è´¥ï¼Œä½¿ç”¨ Spine é¡ºåºæå–")
            chapters = self._extract_from_spine_standard(debug)
        
        if debug:
            print(f"\nğŸ“Š æœ€ç»ˆç« èŠ‚ç»Ÿè®¡:")
            total_length = 0
            for i, (title, content, chapter_id) in enumerate(chapters):
                content_length = len(content)
                total_length += content_length
                print(f"  {i+1:2d}. {title[:50]:<50} | {content_length:>8,} å­—ç¬¦")
            print(f"æ€»å†…å®¹é•¿åº¦: {total_length:,} å­—ç¬¦")
        
        return chapters
    
    def _extract_from_toc_standard(self, debug=False) -> List[Tuple[str, str, str]]:
        """ä½¿ç”¨æ ‡å‡†æ–¹æ³•ä» TOC æå–ç« èŠ‚ - é¿å…å¤æ‚çš„é”šç‚¹å¤„ç†"""
        chapters = []
        processed_files = set()  # è·Ÿè¸ªå·²å¤„ç†çš„æ–‡ä»¶ï¼Œé¿å…é‡å¤
        
        def process_toc_item(item, level=0):
            indent = "  " * level
            
            if isinstance(item, tuple):
                # (Section, children) æ ¼å¼
                section, children = item
                if debug:
                    print(f"{indent}å¤„ç† TOC ç»„: {section.title}")
                
                # å¤„ç†å½“å‰èŠ‚
                if hasattr(section, 'href') and section.href:
                    self._process_single_toc_entry(section, chapters, processed_files, debug, indent)
                
                # å¤„ç†å­èŠ‚
                if children:
                    for child in children:
                        process_toc_item(child, level + 1)
            else:
                # å•ä¸ª TOC æ¡ç›®
                if debug:
                    print(f"{indent}å¤„ç† TOC é¡¹: {item.title}")
                
                if hasattr(item, 'href') and item.href:
                    self._process_single_toc_entry(item, chapters, processed_files, debug, indent)
        
        if debug:
            print(f"å¼€å§‹å¤„ç† {len(self.book.toc)} ä¸ª TOC é¡¹ç›®")
        
        for item in self.book.toc:
            process_toc_item(item)
            
        return chapters
    
    def _process_single_toc_entry(self, toc_entry, chapters, processed_files, debug, indent):
        """å¤„ç†å•ä¸ª TOC æ¡ç›® - ä½¿ç”¨ä¿å®ˆçš„æ–¹æ³•"""
        href = toc_entry.href
        title = toc_entry.title or f"ç« èŠ‚ {len(chapters) + 1}"
        
        if debug:
            print(f"{indent}  å¤„ç†é“¾æ¥: {href}")
        
        # åˆ†ç¦»æ–‡ä»¶åå’Œé”šç‚¹
        if '#' in href:
            file_name, anchor = href.split('#', 1)
        else:
            file_name, anchor = href, None
        
        # æŸ¥æ‰¾å¯¹åº”çš„æ–‡æ¡£é¡¹ç›®
        doc_item = None
        for item in self.book.get_items_of_type(ebooklib.ITEM_DOCUMENT):
            if item.get_name() == file_name:
                doc_item = item
                break
        
        if not doc_item:
            if debug:
                print(f"{indent}    âŒ æœªæ‰¾åˆ°æ–‡æ¡£: {file_name}")
            return
        
        # è·å–æ–‡æ¡£å†…å®¹
        try:
            content = doc_item.get_content().decode('utf-8')
        except Exception as e:
            if debug:
                print(f"{indent}    âŒ è§£ç å¤±è´¥: {e}")
            return
        
        # å…³é”®å†³ç­–ï¼šå¦‚ä½•å¤„ç†é”šç‚¹
        if anchor:
            if debug:
                print(f"{indent}    ğŸ”— å‘ç°é”šç‚¹: {anchor}")
            
            # ä¿å®ˆæ–¹æ³•ï¼šå¦‚æœæ–‡ä»¶å·²ç»è¢«å¤„ç†è¿‡ï¼Œè·³è¿‡ï¼ˆé¿å…é‡å¤ï¼‰
            # å¦‚æœæ–‡ä»¶æœªè¢«å¤„ç†è¿‡ï¼Œæå–æ•´ä¸ªæ–‡ä»¶å†…å®¹ï¼ˆé¿å…å¤æ‚çš„é”šç‚¹åˆ†å‰²ï¼‰
            file_key = f"{file_name}#{anchor}"
            if file_key in processed_files:
                if debug:
                    print(f"{indent}    âš ï¸  é”šç‚¹å·²å¤„ç†ï¼Œè·³è¿‡: {file_key}")
                return
            
            # ç®€å•çš„é”šç‚¹å¤„ç†ï¼šåªå¤„ç†æ˜æ˜¾çš„ç« èŠ‚åˆ†å‰²
            processed_content = self._simple_anchor_processing(content, anchor, debug, indent)
            if processed_content and len(processed_content) > 500:  # ç¡®ä¿æœ‰è¶³å¤Ÿå†…å®¹
                chapters.append((title, processed_content, file_key))
                processed_files.add(file_key)
                if debug:
                    print(f"{indent}    âœ“ æ·»åŠ ç« èŠ‚ (é”šç‚¹): {title} ({len(processed_content)} å­—ç¬¦)")
            else:
                # å¦‚æœé”šç‚¹å¤„ç†å¤±è´¥ï¼Œä½¿ç”¨æ•´ä¸ªæ–‡ä»¶ï¼ˆå¦‚æœæœªå¤„ç†è¿‡ï¼‰
                if file_name not in processed_files:
                    chapters.append((title, content, file_name))
                    processed_files.add(file_name)
                    if debug:
                        print(f"{indent}    âœ“ æ·»åŠ ç« èŠ‚ (æ•´ä¸ªæ–‡ä»¶): {title} ({len(content)} å­—ç¬¦)")
        else:
            # æ— é”šç‚¹ï¼šç›´æ¥ä½¿ç”¨æ•´ä¸ªæ–‡ä»¶
            if file_name not in processed_files:
                chapters.append((title, content, file_name))
                processed_files.add(file_name)
                if debug:
                    print(f"{indent}    âœ“ æ·»åŠ ç« èŠ‚ (æ— é”šç‚¹): {title} ({len(content)} å­—ç¬¦)")
            elif debug:
                print(f"{indent}    âš ï¸  æ–‡ä»¶å·²å¤„ç†ï¼Œè·³è¿‡: {file_name}")
    
    def _simple_anchor_processing(self, content: str, anchor: str, debug=False, indent="") -> Optional[str]:
        """ç®€å•çš„é”šç‚¹å¤„ç† - åªå¤„ç†æ˜æ˜¾çš„æƒ…å†µï¼Œé¿å…å¤æ‚ç®—æ³•"""
        
        # æ–¹æ³•1: æŸ¥æ‰¾ç²¾ç¡®çš„ id æˆ– name å±æ€§
        patterns = [
            rf'<[^>]+id=["\']?{re.escape(anchor)}["\']?[^>]*>',
            rf'<[^>]+name=["\']?{re.escape(anchor)}["\']?[^>]*>',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, content, re.IGNORECASE)
            if match:
                start_pos = match.start()
                
                # æŸ¥æ‰¾ä¸‹ä¸€ä¸ªæ˜æ˜¾çš„ç« èŠ‚åˆ†å‰²ç‚¹ï¼ˆåªæŸ¥æ‰¾æ ‡é¢˜æ ‡ç­¾ï¼‰
                next_heading = re.search(r'<h[1-4][^>]*>', content[start_pos + 100:], re.IGNORECASE)
                if next_heading:
                    end_pos = start_pos + 100 + next_heading.start()
                    extracted = content[start_pos:end_pos].strip()
                    if debug:
                        print(f"{indent}      âœ“ é”šç‚¹åŒ¹é…æˆåŠŸï¼Œæå– {len(extracted)} å­—ç¬¦")
                    return extracted
                else:
                    # æ²¡æ‰¾åˆ°ä¸‹ä¸€ä¸ªæ ‡é¢˜ï¼Œè¿”å›ä»é”šç‚¹åˆ°æ–‡ä»¶æœ«å°¾çš„å†…å®¹
                    extracted = content[start_pos:].strip()
                    if debug:
                        print(f"{indent}      âœ“ é”šç‚¹åŒ¹é…æˆåŠŸï¼Œæå–åˆ°æ–‡ä»¶æœ«å°¾ {len(extracted)} å­—ç¬¦")
                    return extracted
        
        if debug:
            print(f"{indent}      âŒ é”šç‚¹åŒ¹é…å¤±è´¥: {anchor}")
        return None
    
    def _extract_from_spine_standard(self, debug=False) -> List[Tuple[str, str, str]]:
        """ä½¿ç”¨æ ‡å‡†æ–¹æ³•ä» Spine æå–ç« èŠ‚"""
        chapters = []
        
        if debug:
            print(f"ä» Spine æå– {len(self.book.spine)} ä¸ªæ–‡æ¡£")
        
        for i, (item_id, linear) in enumerate(self.book.spine):
            if not linear:  # è·³è¿‡éçº¿æ€§é¡¹ç›®
                continue
                
            item = self.book.get_item_with_id(item_id)
            
            if item and item.get_type() == ebooklib.ITEM_DOCUMENT:
                try:
                    content = item.get_content().decode('utf-8')
                    if content.strip():
                        # ä»å†…å®¹ä¸­æå–æ ‡é¢˜
                        title = self._extract_title_from_content(content) or f"ç« èŠ‚ {len(chapters) + 1}"
                        chapters.append((title, content, item_id))
                        if debug:
                            print(f"  âœ“ æ·»åŠ ç« èŠ‚: {title} (ID: {item_id}, é•¿åº¦: {len(content)})")
                    elif debug:
                        print(f"  âœ— ç©ºå†…å®¹: {item_id}")
                except Exception as e:
                    if debug:
                        print(f"  âœ— è§£ç å¤±è´¥: {item_id} - {e}")
            elif debug:
                if item:
                    print(f"  âœ— éæ–‡æ¡£é¡¹: {item_id} (ç±»å‹: {item.get_type()})")
                else:
                    print(f"  âœ— æœªæ‰¾åˆ°é¡¹ç›®: {item_id}")
                    
        return chapters
    
    def _extract_title_from_content(self, content: str) -> Optional[str]:
        """ä» HTML å†…å®¹ä¸­æå–æ ‡é¢˜"""
        # å°è¯•æå– h1, h2 ç­‰æ ‡é¢˜æ ‡ç­¾
        title_patterns = [
            r'<h[1-6][^>]*>(.*?)</h[1-6]>',
            r'<title[^>]*>(.*?)</title>',
        ]
        
        for pattern in title_patterns:
            match = re.search(pattern, content, re.IGNORECASE | re.DOTALL)
            if match:
                title = re.sub(r'<[^>]+>', '', match.group(1)).strip()
                title = unescape(title)
                if title:
                    return title
        return None
    
    def _print_epub_structure(self):
        """æ‰“å° EPUB æ–‡ä»¶çš„åŸºæœ¬ç»“æ„ä¿¡æ¯"""
        print(f"\nğŸ” EPUB æ–‡ä»¶ç»“æ„åˆ†æ:")
        print(f"=" * 60)
        
        # åŸºæœ¬ä¿¡æ¯
        print(f"ğŸ“š ä¹¦ç±ä¿¡æ¯:")
        title = self.book.get_metadata('DC', 'title')
        author = self.book.get_metadata('DC', 'creator')
        print(f"  æ ‡é¢˜: {title[0][0] if title else 'æœªçŸ¥'}")
        print(f"  ä½œè€…: {author[0][0] if author else 'æœªçŸ¥'}")
        
        # TOC ä¿¡æ¯
        print(f"\nğŸ“‘ ç›®å½•ç»“æ„:")
        print(f"  TOC é¡¹ç›®æ•°: {len(self.book.toc) if self.book.toc else 0}")
        
        # Spine ä¿¡æ¯
        print(f"\nğŸ“„ é˜…è¯»é¡ºåº:")
        print(f"  Spine é¡¹ç›®æ•°: {len(self.book.spine) if self.book.spine else 0}")
        
        # æ–‡æ¡£é¡¹ç›®
        doc_items = list(self.book.get_items_of_type(ebooklib.ITEM_DOCUMENT))
        print(f"\nğŸ“¦ æ–‡æ¡£é¡¹ç›®:")
        print(f"  æ–‡æ¡£æ•°é‡: {len(doc_items)}")
        
        print(f"=" * 60)
    
    def _sanitize_filename(self, filename: str) -> str:
        """æ¸…ç†æ–‡ä»¶åï¼Œç§»é™¤éæ³•å­—ç¬¦"""
        # ç§»é™¤æˆ–æ›¿æ¢éæ³•å­—ç¬¦
        filename = re.sub(r'[<>:"/\\|?*]', '_', filename)
        # ç§»é™¤å¤šä½™çš„ç©ºæ ¼å’Œç‚¹
        filename = re.sub(r'\s+', ' ', filename).strip()
        filename = filename.strip('.')
        # é™åˆ¶é•¿åº¦
        if len(filename) > 100:
            filename = filename[:100]
        return filename or "untitled"
    
    def export_chapters(self, output_dir: str, format_type: str = 'markdown') -> None:
        """
        å¯¼å‡ºæ‰€æœ‰ç« èŠ‚
        
        Args:
            output_dir: è¾“å‡ºç›®å½•
            format_type: è¾“å‡ºæ ¼å¼ ('markdown' æˆ– 'txt')
        """
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        chapters = self.get_chapters()
        
        if not chapters:
            print("âš ï¸  æœªæ‰¾åˆ°ä»»ä½•ç« èŠ‚å†…å®¹")
            return
        
        print(f"ğŸ“š æ‰¾åˆ° {len(chapters)} ä¸ªç« èŠ‚ï¼Œå¼€å§‹å¯¼å‡º...")
        
        # å¯¼å‡ºå›¾ç‰‡èµ„æº
        images_exported = self._export_images(output_path)
        if images_exported:
            print(f"ğŸ–¼ï¸  å¯¼å‡ºäº† {images_exported} ä¸ªå›¾ç‰‡æ–‡ä»¶")
        
        # åˆ›å»ºä¸´æ—¶ç›®å½•ç”¨äº pandoc è½¬æ¢
        with tempfile.TemporaryDirectory() as temp_dir:
            self.temp_dir = temp_dir
            
            for i, (title, content, chapter_id) in enumerate(chapters, 1):
                try:
                    # å¤„ç†å†…å®¹ä¸­çš„å›¾ç‰‡é“¾æ¥
                    processed_content = self._process_image_links(content, format_type)
                    
                    self._export_single_chapter(
                        title, processed_content, i, output_path, format_type
                    )
                except Exception as e:
                    print(f"âŒ å¯¼å‡ºç« èŠ‚ '{title}' å¤±è´¥: {e}")
                    continue
        
        print(f"âœ… å¯¼å‡ºå®Œæˆï¼æ–‡ä»¶ä¿å­˜åœ¨: {output_path}")
    
    def _export_images(self, output_path: Path) -> int:
        """å¯¼å‡º EPUB ä¸­çš„æ‰€æœ‰å›¾ç‰‡ï¼Œä¿æŒåŸå§‹ç›®å½•ç»“æ„"""
        if not self.book:
            return 0
        
        exported_count = 0
        self.image_mapping = {}  # å­˜å‚¨åŸå§‹è·¯å¾„åˆ°æ–°è·¯å¾„çš„æ˜ å°„
        
        for item in self.book.get_items():
            if item.get_type() == ebooklib.ITEM_IMAGE:
                try:
                    # è·å–åŸå§‹å›¾ç‰‡è·¯å¾„
                    original_path = item.get_name()
                    
                    # åˆ›å»ºå®Œæ•´çš„è¾“å‡ºè·¯å¾„ï¼ˆä¿æŒç›®å½•ç»“æ„ï¼‰
                    image_output_path = output_path / original_path
                    
                    # ç¡®ä¿ç›®å½•å­˜åœ¨
                    image_output_path.parent.mkdir(parents=True, exist_ok=True)
                    
                    # ä¿å­˜å›¾ç‰‡
                    with open(image_output_path, 'wb') as f:
                        f.write(item.get_content())
                    
                    # è®°å½•æ˜ å°„å…³ç³»
                    self.image_mapping[original_path] = original_path
                    
                    exported_count += 1
                    print(f"  ğŸ“· å¯¼å‡ºå›¾ç‰‡: {original_path}")
                    
                except Exception as e:
                    print(f"  âŒ å¯¼å‡ºå›¾ç‰‡å¤±è´¥ {item.get_name()}: {e}")
        
        return exported_count
    
    def _process_image_links(self, content: str, format_type: str) -> str:
        """å¤„ç†å†…å®¹ä¸­çš„å›¾ç‰‡é“¾æ¥"""
        import re
        
        if format_type.lower() != 'markdown':
            return content
        
        # æŸ¥æ‰¾æ‰€æœ‰ img æ ‡ç­¾
        img_pattern = r'<img[^>]*src=["\']([^"\']+)["\'][^>]*>'
        
        def replace_img_tag(match):
            img_tag = match.group(0)
            src = match.group(1)
            
            # æ¸…ç†è·¯å¾„ï¼ˆç§»é™¤ ../ ç­‰ç›¸å¯¹è·¯å¾„å‰ç¼€ï¼‰
            clean_src = src
            while clean_src.startswith('../'):
                clean_src = clean_src[3:]
            
            # å°è¯•æå– alt æ–‡æœ¬
            alt_match = re.search(r'alt=["\']([^"\']*)["\']', img_tag, re.IGNORECASE)
            alt_text = alt_match.group(1) if alt_match else "å›¾ç‰‡"
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ˜ å°„å…³ç³»
            if hasattr(self, 'image_mapping') and clean_src in self.image_mapping:
                image_path = self.image_mapping[clean_src]
            else:
                # å¦‚æœæ²¡æœ‰æ˜ å°„ï¼Œä½¿ç”¨åŸå§‹è·¯å¾„
                image_path = clean_src
            
            # è¿”å› Markdown æ ¼å¼çš„å›¾ç‰‡é“¾æ¥ï¼ˆä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼‰
            return f'![{alt_text}]({image_path})'
        
        # æ›¿æ¢æ‰€æœ‰ img æ ‡ç­¾
        processed_content = re.sub(img_pattern, replace_img_tag, content, flags=re.IGNORECASE)
        
        return processed_content
    
    def _export_single_chapter(self, title: str, content: str, index: int, 
                             output_path: Path, format_type: str) -> None:
        """å¯¼å‡ºå•ä¸ªç« èŠ‚"""
        # æ¸…ç†æ ‡é¢˜ä½œä¸ºæ–‡ä»¶å
        safe_title = self._sanitize_filename(title)
        
        # ç”Ÿæˆæ–‡ä»¶å
        if format_type.lower() == 'markdown':
            filename = f"{index:02d}_{safe_title}.md"
            pandoc_format = 'markdown'
        else:
            filename = f"{index:02d}_{safe_title}.txt"
            pandoc_format = 'plain'
        
        output_file = output_path / filename
        
        try:
            # ä½¿ç”¨ pandoc è½¬æ¢ HTML åˆ°ç›®æ ‡æ ¼å¼
            converted_content = pypandoc.convert_text(
                content,
                pandoc_format,
                format='html',
                extra_args=['--wrap=none']  # ä¸è‡ªåŠ¨æ¢è¡Œ
            )
            
            # å†™å…¥æ–‡ä»¶
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(converted_content)
            
            print(f"âœ“ å·²å¯¼å‡º: {filename}")
            
        except Exception as e:
            print(f"âŒ è½¬æ¢ç« èŠ‚ '{title}' æ—¶å‡ºé”™: {e}")
            # å¦‚æœ pandoc è½¬æ¢å¤±è´¥ï¼Œå°è¯•ç®€å•çš„ HTML æ ‡ç­¾æ¸…ç†
            self._fallback_export(content, output_file, title)
    
    def _fallback_export(self, content: str, output_file: Path, title: str) -> None:
        """å¤‡ç”¨å¯¼å‡ºæ–¹æ³•ï¼ˆç®€å•çš„ HTML æ ‡ç­¾æ¸…ç†ï¼‰"""
        try:
            # ç®€å•çš„ HTML æ ‡ç­¾æ¸…ç†
            import html
            
            # ç§»é™¤ HTML æ ‡ç­¾
            clean_content = re.sub(r'<[^>]+>', '', content)
            # è§£ç  HTML å®ä½“
            clean_content = html.unescape(clean_content)
            # æ¸…ç†å¤šä½™çš„ç©ºç™½
            clean_content = re.sub(r'\n\s*\n', '\n\n', clean_content)
            clean_content = clean_content.strip()
            
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(clean_content)
            
            print(f"âœ“ å·²å¯¼å‡º (å¤‡ç”¨æ–¹æ³•): {output_file.name}")
            
        except Exception as e:
            print(f"âŒ å¤‡ç”¨å¯¼å‡ºä¹Ÿå¤±è´¥äº†: {e}")


@click.command()
@click.argument('epub_file', type=click.Path(exists=True))
@click.option('--output', '-o', default='./output', 
              help='è¾“å‡ºç›®å½• (é»˜è®¤: ./output)')
@click.option('--format', '-f', type=click.Choice(['markdown', 'txt']), 
              default='markdown', help='è¾“å‡ºæ ¼å¼ (é»˜è®¤: markdown)')
@click.option('--debug', '-d', is_flag=True, help='å¯ç”¨è°ƒè¯•æ¨¡å¼')
def main(epub_file: str, output: str, format: str, debug: bool):
    """
    EPUB ç« èŠ‚å¯¼å‡ºå·¥å…· v2.0
    
    åŸºäºæ ‡å‡†æ–¹æ³•çš„ç®€åŒ–å®ç°ï¼Œé¿å…å¤æ‚çš„è‡ªåˆ¶é”šç‚¹å¤„ç†ç®—æ³•
    
    ç¤ºä¾‹:
        python epub_exporter_v2.py book.epub
        python epub_exporter_v2.py book.epub -o ./chapters -f txt -d
    """
    try:
        print(f"ğŸš€ å¼€å§‹å¤„ç† EPUB æ–‡ä»¶: {epub_file}")
        
        exporter = EpubExporterV2(epub_file)
        
        if debug:
            print("ğŸ” è°ƒè¯•æ¨¡å¼å·²å¯ç”¨")
            # å…ˆè¿è¡Œè°ƒè¯•åˆ†æ
            chapters = exporter.get_chapters(debug=True)
            print(f"\næ˜¯å¦ç»§ç»­å¯¼å‡ºï¼Ÿ(y/n): ", end="")
            response = input().strip().lower()
            if response != 'y':
                print("å·²å–æ¶ˆå¯¼å‡º")
                return
        
        exporter.export_chapters(output, format)
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        sys.exit(1)


if __name__ == '__main__':
    main()
